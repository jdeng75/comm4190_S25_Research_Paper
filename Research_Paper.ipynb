{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb4f5c4-7caf-4a22-8acc-cde24395c8f4",
   "metadata": {},
   "source": [
    "# Simulating Tool for Doctor-Patient Interaction: An Analysis of AI Chatbots in Medical Care Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c92784-684a-4275-b60e-d150b07f2042",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb61cdd-ebac-4cc8-ac4a-08d73ae311cd",
   "metadata": {},
   "source": [
    "As artificial intelligence technologies, especially Large Language Models (LLMs), become increasingly integrated into everyday life, their influence on how people prepare for and understand healthcare interactions is becoming more significant. LLMs such as ChatGPT, Claude, Deepseek, and others are now capable of engaging in fluid, context-aware conversations. This makes them potentially useful tools in helping patients navigate the often overwhelming and highly asymmetrical world of doctor-patient communication.\n",
    "\n",
    "Doctor visits are typically time-constrained and emotionally charged, with many patients leaving appointments with unanswered questions, misunderstood information, or anxiety about what they should do next. These issues are especially pronounced for individuals with lower health literacy, language barriers, or communication anxiety. In this context, LLMs might offer low-cost, always-available support to help patients prepare for their appointments, clarify medical language, and even practice expressing sensitive concerns.\n",
    "\n",
    "This paper focuses on the communicative role LLMs could play in supporting—not replacing—doctor-patient interaction. Drawing from relevant literature and a series of simulated patient-AI interactions, I analyze how current LLMs perform in this role, what kinds of communication they facilitate, and what limitations or risks they pose. My goal is to critically explore how AI might shape the future of healthcare communication from the patient's perspective. \n",
    "\n",
    "For my patient-AI interactions, I will be simulating a patient who recently got diagnosed with stage 4 non-Hodgkin's lymphoma and is trying to understand their diagnosis better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d65ee-a680-4c21-871d-15d383fa5fc9",
   "metadata": {},
   "source": [
    "## Literature Review: AI Applications in Doctor-Patient Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ca07d-f2a6-432c-b755-8b5c785a2c01",
   "metadata": {},
   "source": [
    "## Case Study: Diagnosis Conversations with AI Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa8efa-4779-4a1e-a62d-68c4a1ebf326",
   "metadata": {},
   "source": [
    "To understand the basis of this project and first-hand insight into the experience of using AI chatbots for diagnosis discussions for patients, I wanted to engage with various LLMs to see the difference in their response: **Claude-3.7, ChatGPT-4.1, Deepseek.**\n",
    "\n",
    "To minimize any random variation in responses, I stuck to three questions to prompt each LLM.\n",
    "\n",
    "1. \"I was diagnosed with stage 4 non-Hodgkin's lymphoma by my doctor. I'm scared. What is this, how serious is it, what should I do, what should I ask my doctor?\n",
    "2. What is R-chop, lymphadenopathy, and immunophenotyping?\n",
    "3. Is all of this safe.\n",
    "\n",
    "\n",
    "This ensures that the model understands my specific diagnosis. With the second prompt, I use these questions to understand if each model can efficiently explain these medical jargons. And for the third prompt, I want to use this question to see how \"empathetic\" the model can be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f271e52-35ac-4e4f-959a-d9497759b944",
   "metadata": {},
   "source": [
    "### Coversations with Claude-3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ff2b6-d4ed-41c5-b367-24bb5a273356",
   "metadata": {},
   "source": [
    "Initially, I used anthropic/claude-3.7. My first interaction was framed around a common patients experience: anxiety and uncertainty before another doctor's visit. I prompted Claude with: \n",
    "</br>\n",
    "\n",
    "> I was diagnosed with stage 4 non-Hodgkin's lymphoma by my doctor. I'm scared. What is this, how serious is it, what should I do, what should I ask my doctor?\"\n",
    "\n",
    "The first thing I noticed is the first sentence. It was bolded and in larger font than the rest of the other fonts, saying, **\"I'm sorry to hear about your diagnosis.\"** This model was highly empathetic, saying how it wanted to first acknowledge the diagnosis.\n",
    "\n",
    "Aside from the empathetic interaction, Claude's response was highly structured and supportive, offering a set of questions organized around system tracking, life, and potential. It suggested what to do next:\n",
    "\n",
    "- Connect with doctor\n",
    "- take notes\n",
    "- consider a second opinion\n",
    "\n",
    "Claude also offered meta-level communication adive: it encouraged me to write down my questions ahead of time and share a written list with the provider. This attention to process, not jjust content, stood out as a reflection of Claude's human-centered design.\n",
    "\n",
    "I also like how it structured **\"questions to ask your doctor\"**:\n",
    "\n",
    "- What is my treatment plan\n",
    "- How will treatment affect my daily life?\n",
    "\n",
    "There are more useful responses that Claude-3.7 created. All of which a normal patient would ask their physicians.\n",
    "\n",
    "Claude maintained a cautious yet affirming tone. It offered  sampled language use and emphasized the importance of self-advocacy in healthcare. It maintained boundaries while still offering support.\n",
    "\n",
    "As for helping me understand the key terms in this diagnosis, it was also well structured and short. It would explain the term, and explain how it was relevant to my diagnosis.\n",
    "\n",
    "When asking if these ere all safe, it kept the responses short and kept emphasizing that I should talk to my physician.\n",
    "\n",
    "Overall, Claude-3.7's communication support was empathetic, articulate, and boundaries-aware. It demonstrated how a well-trained LLM can **simulate relational scaffolding without overstepping into dangerous territory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ebb687-3f51-404f-9d68-0bf0688992e0",
   "metadata": {},
   "source": [
    "<img src=\"Claude-3.7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd96657-9ddb-4a21-8503-a6962a012609",
   "metadata": {},
   "source": [
    "### Conversations with ChatGPT-4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77cf06-dbdf-4b7d-83fc-d5239d4f541c",
   "metadata": {},
   "source": [
    "GPT-4.1 feels similarly structured to Claude 3.7, but its responses are even more concise. Unlike Claude, GPT-4.1 didn't start with a bolded heading with encouraging words, but it did open with a compassionate statement: **\"I'm very sorry to hear about your diagnosis.\"**\n",
    "\n",
    "The **What should you do** section mirrored Claude's suggestions. \n",
    "\n",
    "- Stay informed\n",
    "- Talk to a doctor\n",
    "- Consider a second option\n",
    "- Prioritize self-care\n",
    "\n",
    "However, GPT-4.1 stood out in how it organized follow-up questions for a doctor. The questions were grouped by themes: treatment, diagnosis, support, and more. I found this format clearer and more useful than Claude's.\n",
    "\n",
    "The **Final Thoughts** section from GPT-4.1 felt more intense. It emphasized the seriousness of the diagnosis several times, which made me feel a bit uneasy. I don't think I would like to hear about how serious it was... especially if I knew I had stage 4 cancer. Still, it offered reassurance by reminding me that I'm not alone and that help is available.\n",
    "\n",
    "The explanation of medical jargon was noticeably shorter and more simplified than Claude's. I think this was intentional so it wouldn't overwhelm a patient or risk the delivery of inaccurate information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e09231-7ec5-4f05-8b11-f4b0ddef968b",
   "metadata": {},
   "source": [
    "<img src=\"GPT-4.1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0df6e6-7ac5-4a01-a3f7-d8e0a049db1c",
   "metadata": {},
   "source": [
    "### Conversations with DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23db84-c33c-409d-b5ae-fdb0f2663fdc",
   "metadata": {},
   "source": [
    "Deepseek opened in a similar way to GPT-4.1, expressing condolences and acknowledging how scary this time must be. Like the others, it emphasized the seriousness of the diagnosis—but perhaps even more directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c4ccb-cdc0-4424-b918-2c4de5a0b3b4",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00841456-f26c-430f-a3fc-7b84f63928f9",
   "metadata": {},
   "source": [
    "The conversations with Claude-3.7, ChatGPT-4.1, and Deepseek shows the benefits and negatives of using AI chatbox in a diagnosis setting for doctor-patient interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d7e98-d605-4749-8786-72bf8cb24f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1bcbc1-6eb3-42d5-8cae-3188c581af27",
   "metadata": {},
   "source": [
    "Let us remind ourselves that the purpose of AI tools in diagnosis settings with doctor-patient interactions is not to replace a doctor's job. It is only to enhance and act as a useful, effective tool for patients who want to gain more control of their health. When we place patients at the center and allow them to ask unlimited questions, it helps improve healthcare for all and use **AI for good.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
